	import tensorflow as tf
	tf.set_random_seed(777)  # for reproducibility # 랜덤 수 777개의 set을 만든다.



	x_data = [[1, 2],       
	          [2, 3],
	          [3, 1],
	          [4, 3],
	          [5, 3],
	          [6, 2]]
	y_data = [[0],           #y_data는 0과 1값만 갖는다. Pass/fail
	          [0],
	          [0],
	          [1],
	          [1],
	          [1]]

	

	# placeholders for a tensor that will be always fed.
	X = tf.placeholder(tf.float32, shape=[None, 2])  # x_data와 y_data의 전체의 개수는 정해놓지 않는다.
	Y = tf.placeholder(tf.float32, shape=[None, 1])  # Shape을 정하고 계산을 실행할 때 값을 넣어줄 자리를 지정한다.
	

	W = tf.Variable(tf.random_normal([2, 1]), name='weight')  #w는 입력 이미지 벡터의 크기가2, 출력 숫자 클래스가 1 이다.
	b = tf.Variable(tf.random_normal([1]), name='bias')       #b는 1차원 벡터이다. 
	

	# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))
	hypothesis = tf.sigmoid(tf.matmul(X, W) + b)  #sigmoid로 직접 구현
	

	# cost/loss function
	cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *       # cost정의 cost함수 구현
	                       tf.log(1 - hypothesis))             
	

	train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)  #학습 속도 0.01의 경사 하강법 알고리즘을 사용하여 cost를 최소화한다.
	

	# Accuracy computation
	# True if hypothesis>0.5 else False
	predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)  #hypothesis가 0.5보다 크면 pass이다. tf.float32으로 casting을 하면 pass는 1 fail은 0이 된다.
	accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))  #predicted(예측한 값)과 Y의 값이 같은지 pass(1),fail(0)로 판단하고 계산한다.
	

	# Launch graph
	with tf.Session() as sess:
	    # Initialize TensorFlow variables
	    sess.run(tf.global_variables_initializer())  #그래프 안에 있는 값을 초기화 한다.
	


	    for step in range(10001):
	        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})  #train을 x_data와 y_data를 가지고 실행시킨다. 그 때 Cost의 값을 val로 저장한다. 
	        if step % 200 == 0:         #200번 마다 한 번씩 step의 cost값을 출력한다.
	            print(step, cost_val)
	

	    # Accuracy report
	    h, c, a = sess.run([hypothesis, predicted, accuracy],  # 예측 값과 y_data를 비교해서 accuracy는 얼마가 나올 것인가 출력한다.
	                       feed_dict={X: x_data, Y: y_data})
	    print("\nHypothesis: ", h, "\nCorrect (Y): ", c, "\nAccuracy: ", a)  # 정확도 측정
	

