import tensorflow as tf
import numpy as np

tf.set_random_seed(0)  #다시 수행해도 동일하게 재연될 수 있도록 random_seed 특정한 값으로 초기화 

x_data = [1.,2.,3.,4.]  #x_data, y_data 설정
y_data = [1.,3.,5.,7.]

W = tf.Variable(tf.random_normal([1],-100.,100.))  #정규분포를 따르는 random number 한 개짜리로 변수만들어서 W에 할당 

for step in range(300):  #gradient 300회 수행
    hypothesis = W*X
    cost = tf.reduce_mean(tf.square(hypothesis - Y)) #cost function
    
    alpha = 0.01
    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W,X)-Y,X))  #Gradient descent
    descent = W - tf.multiply(alpha,gradient)  #새로운 W값
    W.assign(descent)  #W값 update
    
    if step % 10 == 0:  #10번에 한 번씩 W와 X값 확인
        print('{:5} | {:10.4f} | {:10.6f}'.format(
            step, cost.numpy(), W.mumpy()[0]))
            
    #cost는 점점 급속하게 줄다가 0으로 수렴
    #W값 임의값에서 특정값(1)으로 수렴
    #초기의 cost값 w값 다른 값이더라도 cost값은 0으로 수렴하고 w값은 특정값으로 수렴하게 된다.
